{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fL0j-MlukmQc"
   },
   "source": [
    "This brief tutorial explains some concepts related to the Python library `scikit-learn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTNcSknVkmQg"
   },
   "source": [
    "# What is Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znTrvOFAkmQl"
   },
   "source": [
    "- Python is an interpreted programming language.\n",
    "- Its name comes from its creator, [Guido van Rossum](https://es.wikipedia.org/wiki/Guido_van_Rossum), who was a fan of the surreal comedy troupe [Monty Python](https://es.wikipedia.org/wiki/Monty_Python).\n",
    "- Main characteristics:\n",
    "  - Object oriented programming.\n",
    "  - Imperative programming.\n",
    "  - Functional programming.\n",
    "  - Platform independent and open source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nReZ280bkmQp"
   },
   "source": [
    "# Python Integrated Development Environments (IDEs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS3EaW6MkmQs"
   },
   "source": [
    "- IDEs for Python\n",
    "  - [Sublime Text](http://www.sublimetext.com/)\n",
    "  - [PyCharm](https://www.jetbrains.com/pycharm/)\n",
    "  - [Spyder](https://github.com/spyder-ide/spyder)\n",
    "  - [Visual Code](https://code.visualstudio.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1RmDwyFkmQw"
   },
   "source": [
    "# `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dEncGbCkmQz"
   },
   "source": [
    "- Library providing a wide set of supervised and unsupervised learning algorithms, through a consistent `python` interface.\n",
    "- Published under BSD license and distributed in many Linux distributions, it favours teaching and commercial use.\n",
    "- This library is integrated with [`SciPy`](http://www.scipy.org/) (*Scientific Python*), together with other products:\n",
    "  - [**NumPy**](http://www.numpy.org/)\n",
    "  - [**Matplotlib**](http://matplotlib.org/)\n",
    "  - [SymPy](https://simpy.readthedocs.org/en/latest/)\n",
    "  - [**Pandas**](http://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBrLyL5VkmQ8"
   },
   "source": [
    "# Features of `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFy7iWrzkmQ_"
   },
   "source": [
    "- This library is focused in constructing the models, not in loading and manipulating data. [NumPy](http://www.numpy.org/) and [Pandas](http://pandas.pydata.org/) are the ones to use for dealing with the data. Some of the things we can do with `scikit-learn` are:\n",
    "  - Clustering.\n",
    "  - Cross-validation.\n",
    "  - Synthetic datasets.\n",
    "  - Dimensionality reduction.\n",
    "  - Ensemble methods.\n",
    "  - Feature selection.\n",
    "  - Parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhQ22VymkmRC"
   },
   "source": [
    "- The main advantages of `scikit-learn` include:\n",
    "  - Consistent API for the different machine learning methods.\n",
    "  - All methods provide many hyper-parameters to be configured.\n",
    "  - Awesome documentation.\n",
    "  - Very active development.\n",
    "  - Very active community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wGMBcA0kmRF"
   },
   "source": [
    "Jupyter Notebooks \n",
    "==================\n",
    "\n",
    "* You can run a `Cell` using ``[shift] + [Enter]`` or using the button `Play` in the toolbar.\n",
    "\n",
    "![](images/ipython_run_cell.png)\n",
    "\n",
    "* You can obtain help about a function or an object pressing ``[shift] + [tab]`` after the opening brackets ``function(``\n",
    "\n",
    "![](images/ipython_help-1.png)\n",
    "\n",
    "* You can also get help by using ``function?``\n",
    "\n",
    "![](images/ipython_help-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8u_fDSikmRI"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89chj8VYkmRJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3YVv9nskmRZ"
   },
   "source": [
    "With these lines, we import the neccesary libraries for our example. `pandas` will be used to read the data, `numpy` will be used to work with data as matrices, `matplotlib` will be used to make the plots and, from `scikit-learn`, in this case, we will use a classification method based on the nearest neigbours and some preprocessing functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3g1A_Q1kmRb"
   },
   "source": [
    "## matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Of8ssHikmRd"
   },
   "source": [
    "A very important part of machine learning is data visualization. The most common tool for that in Python is [`matplotlib`](http://matplotlib.org). It is a very flexible package and we will study now some of its elements.\n",
    "\n",
    "Given that we are using Jupyter notebooks, we need to consider one the [magic commands](https://ipython.org/ipython-doc/3/interactive/magics.html) of IPython, the \"*matoplotlib inline*\" mode, which will *plots* directly on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjdnWroWkmRg"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEjMGfbCkmRs"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9BNPqtPkmR7"
   },
   "outputs": [],
   "source": [
    "# Drawing a line\n",
    "x = np.linspace(0, 10, 100)\n",
    "plt.plot(x, np.sin(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdk4UPJ3kmSG"
   },
   "source": [
    "In Python, generally, it is not needed to use ';' at the end of every line. However, when drawing an *inline* plot, we can use ';' to avoid seeing the normal output of *matplotlib* and to see only the figure.\n",
    "Try to run the previous example but removing the ';'. What difference do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0oVdTzBkmSJ"
   },
   "outputs": [],
   "source": [
    "# Drawing a scatter\n",
    "x = np.random.normal(size=500)\n",
    "y = np.random.normal(size=500)\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3GX2Lw7kmSS"
   },
   "outputs": [],
   "source": [
    "# Showing the images using imshow\n",
    "x = np.linspace(1, 12, 100)\n",
    "y = x[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t6refx1kmSf"
   },
   "source": [
    "The numpy method `np.newaxis` creates a new axis in the array. Try to print the dimensionality of `x` and `y` using the numpy method `.shape` and check the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAepaV-akmSg"
   },
   "outputs": [],
   "source": [
    "im = y * np.sin(x) * np.cos(y)\n",
    "print(im.shape)\n",
    "\n",
    "# - The default origin is at the upper left part\n",
    "plt.imshow(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyBwscp3kmSr"
   },
   "source": [
    "What can you see in the image?\n",
    "\n",
    "It is a mix of sin and cosine functions.\n",
    "\n",
    "If you have any doubts, you can always [ask Google](https://www.google.es/search?dcr=0&ei=cGr8WbKFNsmTa_b1n6AI&q=sin%28x%29*cos%28y%29+from+-6+to+6&oq=sin%28x%29*cos%28y%29+from+-6+to+6&gs_l=psy-ab.3...5574.8328.0.8486.6.5.1.0.0.0.79.355.5.5.0....0...1.1.64.psy-ab..0.0.0....0.3Kq-XpUPDRs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypvfHAFFkmSt"
   },
   "outputs": [],
   "source": [
    "# Prepare a countour plot\n",
    "# - The origin now is at the bottom left part\n",
    "plt.contour(im);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_boY2mHkmS3"
   },
   "outputs": [],
   "source": [
    "# 3D Plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "ax = plt.axes(projection='3d')\n",
    "xgrid, ygrid = np.meshgrid(x, y)\n",
    "ax.plot_surface(xgrid, ygrid, im, cmap=plt.cm.viridis, cstride=2, rstride=2, linewidth=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKcP8l57kmTC"
   },
   "source": [
    "There are many plots available. You can explore them by using the [matplotlib gallery](http://matplotlib.org/gallery.html).\n",
    "\n",
    "Try some of the examples, such as this one `https://matplotlib.org/mpl_examples/shapes_and_collections/path_patch_demo.py`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmauLxFhkmTF"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demo of a PathPatch object.\n",
    "\"\"\"\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "Path = mpath.Path\n",
    "path_data = [\n",
    "    (Path.MOVETO, (1.58, -2.57)),\n",
    "    (Path.CURVE4, (0.35, -1.1)),\n",
    "    (Path.CURVE4, (-1.75, 2.0)),\n",
    "    (Path.CURVE4, (0.375, 2.0)),\n",
    "    (Path.LINETO, (0.85, 1.15)),\n",
    "    (Path.CURVE4, (2.2, 3.2)),\n",
    "    (Path.CURVE4, (3, 0.05)),\n",
    "    (Path.CURVE4, (2.0, -0.5)),\n",
    "    (Path.CLOSEPOLY, (1.58, -2.57)),\n",
    "    ]\n",
    "codes, verts = zip(*path_data)\n",
    "path = mpath.Path(verts, codes)\n",
    "patch = mpatches.PathPatch(path, facecolor='r', alpha=0.5)\n",
    "ax.add_patch(patch)\n",
    "\n",
    "# plot control points and connecting lines\n",
    "x, y = zip(*path.vertices)\n",
    "line, = ax.plot(x, y, 'go-')\n",
    "\n",
    "ax.grid()\n",
    "ax.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYB3a8mfkmTO"
   },
   "source": [
    "# Some samples with the `iris` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvQu_Hi7kmTP"
   },
   "source": [
    "We are going to use a typical example in *machine learning* tutorials, the `iris` dataset. In this dataset, there are three classes to be predicted, which are three different species of the iris flower, in such a way that, for every flower, four measurements or input variables are extracted (petal and sepal length and width, in cm). The three species to be predicted are iris *setosa*, iris *virginica* and iris *versicolor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8vZQSSkkmTU"
   },
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9UyNiSNkmTX"
   },
   "source": [
    "As previously discussed, we will use [Pandas](http://pandas.pydata.org/) to read data. This library has a method, `read_csv`, which is able to read data from a `csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOdPza20kmTZ"
   },
   "source": [
    "The method `read_csv` from `pandas` can be used in two ways: the csv file can have a row with the name of the variables or we can specify the names of the variables as an argument. In this case, we will use the second mode. We create an *array* with the name of the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1uZomH-kmTb"
   },
   "outputs": [],
   "source": [
    "name_variables = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izCFmsI5kmTl"
   },
   "source": [
    "and we read the array with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNBYOVk-kmTm"
   },
   "outputs": [],
   "source": [
    "iris = pd.read_csv('data/iris.csv', names = name_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqscgdvPkmTw"
   },
   "source": [
    "`iris` is an object of the class [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) from `pandas`. We could have considered `header=None`, in such a way that `read_csv` would have assigned a default name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLpEl837kmTx"
   },
   "source": [
    "## Inspecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXnAPRq8kmTz"
   },
   "source": [
    "Before anything, it is important to start with an **inspection** of the data. If we just want to see the header of the dataset, we can use the method `head(n)`, which return a `DataFrame` with the first `n` patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsaUCA7XkmT1"
   },
   "outputs": [],
   "source": [
    "print(iris.head(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajyaNw2AkmT9"
   },
   "source": [
    "These data have four dimensions, but we can visualize one or two of these dimensions using a histogram or a scatter. First, we activate the *matplotlib inline* mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grG0Zze1kmUA"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4T-a5ZpkmUG"
   },
   "outputs": [],
   "source": [
    "variable_x = 3\n",
    "colors = ['blue', 'red', 'green']\n",
    "iris_target_names = np.unique(iris['class'])\n",
    "\n",
    "for index, color in zip(range(len(iris_target_names)), colors): # what does zip do?\n",
    "    #We separate the set of every class\n",
    "    patterns = (iris['class']==iris_target_names[index]) # This comparison will be explained later\n",
    "    plt.hist(iris.values[patterns, variable_x], label=iris_target_names[index], color=color)\n",
    "\n",
    "plt.xlabel(name_variables[variable_x])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tKDfHGIkmUQ"
   },
   "source": [
    "Remember that the variables were *['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']*, can you modify the previous code to show the sepal_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlsP5LevkmUR"
   },
   "source": [
    "Now we are going to show in a plot the relationship between two input variables, so that we can see if the characteristics of the patterns make them linearly separable. You can try different combinations of the variables by modifying the values of *variable_x* and *variable_y*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-1T7Pi5kmUS"
   },
   "outputs": [],
   "source": [
    "variable_x = 1 \n",
    "variable_y = 0\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for indice, color in zip(range(len(iris_target_names)), colors):\n",
    "    patterns = (iris['class']==iris_target_names[indice])\n",
    "    plt.scatter(iris.values[patterns, variable_x], \n",
    "                iris.values[patterns, variable_y],\n",
    "                label=iris_target_names[indice],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(name_variables[variable_x])\n",
    "plt.ylabel(name_variables[variable_y])\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejWyIXixkmUc"
   },
   "source": [
    "Have you found a good combination of the variables?\n",
    "It is tedious to try all the combinations, and we have few variables in this example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMfc30RLkmUd"
   },
   "source": [
    "### Scatterplot matrices\n",
    "\n",
    "Instead of creating separated scatterplots, data scientists usually consider **scatterplot matrices**.\n",
    "\n",
    "These matrices show the scatter plots between all the features of the dataset, together with the histograms to see the distributions of all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvbtI_b6kmUg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from pkg_resources import parse_version\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(iris['class'])\n",
    "class_numbers = le.transform(iris['class'])\n",
    "\n",
    "iris_df = pd.DataFrame(iris[name_variables], columns=name_variables)\n",
    "\n",
    "#For pandas>0.16 the method has to be called differently\n",
    "if(parse_version(pd.__version__) > parse_version('0.16')):\n",
    "    pd.plotting.scatter_matrix(iris_df, c=class_numbers, figsize=(8, 8));\n",
    "else:\n",
    "    pd.tools.plotting.scatter_matrix(iris_df, c=class_numbers, figsize=(8, 8));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbDOeFjEkmUn"
   },
   "source": [
    "## Working with numpy matrices (`ndarray`)  and `DataFrame` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h23HUk0WkmUo"
   },
   "source": [
    "[`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) objects are the *datasets* the we are going to use. They can perform a lot of operations automatically, helping to transform the variables very easilly. Internally, the dataset is stored as 2D array of `numpy` (class [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)). The access of the elements in a [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) is a bit easier than using the [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) version. We can use the attribute `values` for accessing the `numpy` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIQMddWrkmUq"
   },
   "outputs": [],
   "source": [
    "print(iris['sepal_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zT6_fJnkmUx"
   },
   "outputs": [],
   "source": [
    "print(iris[name_variables[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PUCe1LBkmU6"
   },
   "outputs": [],
   "source": [
    "iris_array = iris.values\n",
    "print(iris_array[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFvnAr0qkmVA"
   },
   "source": [
    "The syntax for indexing an [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) object is the following one:\n",
    "- `array[i,j]`: value of row `i` column `j`.\n",
    "- `array[i:j,k]`: another `ndarray` with the submatrix containing the rows from `i` to `j-1` and column `k`.\n",
    "- `array[i:j,k:l]`: another `ndarray` with the submatrix containing the rows from `i` to `j-1` and columns from `k` to `l-1`.\n",
    "- `array[i:j,:]`: another `ndarray` with the submatrix containing the rows from `i` to `j-1` and **all** the columns`.\n",
    "- `array[:,i:j]`: another `ndarray` with the submatrix containing **all** the rows and columns from `i` to `j-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQq8VFaykmVB"
   },
   "outputs": [],
   "source": [
    "# Showing the array is less fancy\n",
    "iris_array[0:2,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zy-exOpPkmVW"
   },
   "outputs": [],
   "source": [
    "# The \"pandas\" way is always better looking\n",
    "iris[0:2][name_variables[2:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnXpYY9ykmVb"
   },
   "outputs": [],
   "source": [
    "iris_array[1:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYCig6S_kmVh"
   },
   "outputs": [],
   "source": [
    "iris[1:6][name_variables[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLFTlXE0kmVn"
   },
   "source": [
    "Access to the `ndarray` is, in general, a bit easier, because we do not require the name of the variables. Now, we are going to play with a matrix of random numbers, to see some additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMAFvMPRkmVo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Random number seed (for reproducibility)\n",
    "rnd = np.random.RandomState(seed=123)\n",
    "\n",
    "# Generating a random matrix\n",
    "X = rnd.uniform(low=0.0, high=1.0, size=(3, 5))  # 3x5 dimensional\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFB6twU0kmVt"
   },
   "source": [
    "(note that arrays in numpy are indexed starting from 0, as almost all structures in Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AnYm6HpkmVv"
   },
   "outputs": [],
   "source": [
    "# Access to the elements\n",
    "\n",
    "# Obtaining a single element\n",
    "# (first row, first column)\n",
    "print(X[0, 0])\n",
    "\n",
    "# Obtaining a row\n",
    "# (second row)\n",
    "print(X[1])\n",
    "\n",
    "# Obtaining a column\n",
    "# (second column)\n",
    "print(X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zB5PNw8AkmV1"
   },
   "source": [
    "$$\\begin{bmatrix}\n",
    "    1 & 2 & 3 & 4 \\\\\n",
    "    5 & 6 & 7 & 8\n",
    "\\end{bmatrix}^T\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "    1 & 5 \\\\\n",
    "    2 & 6 \\\\\n",
    "    3 & 7 \\\\\n",
    "    4 & 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEsNlOGTkmV1"
   },
   "outputs": [],
   "source": [
    "# Obtaining the transpose\n",
    "print(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-HoD5WEkmV9"
   },
   "outputs": [],
   "source": [
    "# Create a row vector of numbers with same separation in a predefined range\n",
    "y = np.linspace(start=0, stop=12, num=5)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGQ63tGSkmWE"
   },
   "outputs": [],
   "source": [
    "# Transform the row vector into a column vector\n",
    "print(y[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxWmLgCdkmWJ"
   },
   "outputs": [],
   "source": [
    "# Obtain the shape of an array and modify it\n",
    "\n",
    "# Random array\n",
    "rnd = np.random.RandomState(seed=123)\n",
    "X = rnd.uniform(low=0.0, high=1.0, size=(3, 5))  # a 3 x 5 array\n",
    "\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(X.reshape(5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gBDPGxukmWO"
   },
   "outputs": [],
   "source": [
    "# Indexing according to a set of given numbers\n",
    "indices = np.array([3, 1, 0])\n",
    "print(indices)\n",
    "X[:, indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpfiSEOZkmWT"
   },
   "source": [
    "## Vectorizing operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvuwGDuHkmWU"
   },
   "source": [
    "In `scikit-learn`, as in other programming languages such as R or Matlab, we have to try, when possible, to *vectorize* operations. That is, using matrix operations instead of loops that iterate over the arrays. The reason is that this type of operations are much more optimized and that the process of referencing *arrays* can take a lot time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdCx8BcgkmWV"
   },
   "source": [
    "Imagine that we want to print the sepal area of all the flowers. Compare the difference between a `for` loop and matrix operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EsEBKJJkmWX"
   },
   "outputs": [],
   "source": [
    "# Generating an array with sepal area (length*width), using a for:\n",
    "\n",
    "# Create an empty array\n",
    "sepalAreaArray = np.empty(iris_array.shape[0])\n",
    "\n",
    "# For loop\n",
    "for i in range(iris_array.shape[0]):\n",
    "    sepalAreaArray[i] = iris_array[i,0] * iris_array[i,1]\n",
    "    \n",
    "print(sepalAreaArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nC9KUvjbkmWc"
   },
   "outputs": [],
   "source": [
    "# Generating an array with sepal area (length*width), using matrix operations:\n",
    "sepalAreaArray = iris_array[:,0] * iris_array[:,1]\n",
    "print (sepalAreaArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzyRSv6lkmWj"
   },
   "source": [
    "What is more, `ndarray` accept logical operations that return the `ndarray` resulting from applying the logical operation over all the elements:\n",
    "*Which patterns have the petal length (variable 2) higher than 5 units?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cK5k5sIPkmWj"
   },
   "outputs": [],
   "source": [
    "iris_array[:,2] > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XT08w6IMkmWo"
   },
   "source": [
    "What is more, this `ndarray` can be used to index the original `ndarray`:\n",
    "*Which is the class of the patterns that have the petal length (variable 2) higher than 5 units?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNvbsL3hkmWp"
   },
   "outputs": [],
   "source": [
    "iris_array[iris_array[:,2] > 5,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpsYWgrlkmWu"
   },
   "source": [
    "Imagine now that we want to print the sepal length of the flowers whose sepal length is higher than 2. Compare the `for` version and the vectorized version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlLOXZUDkmWv"
   },
   "outputs": [],
   "source": [
    "# Print the sepal length higher than 2, using a for:\n",
    "iris_array = iris.values\n",
    "for i in range(0,iris_array.shape[0]):\n",
    "    valueSepal = iris_array[i,0]\n",
    "    if valueSepal > 2:\n",
    "        print(valueSepal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCbrIHsWkmW1"
   },
   "outputs": [],
   "source": [
    "# Print the sepal length higher than 2, using matrix operations:\n",
    "print(iris_array[ iris_array[:,0] > 2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWTNCuZikmW6"
   },
   "source": [
    "We can use other additional functions with `ndarray`. For example, the functions [`numpy.mean`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html) and [`numpy.std`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html) which calculate the mean and the standard deviation of the `ndarray`.\n",
    "\n",
    "Finally, we can apply matrix operations over the `ndarray` in a very easy and optimized way. The function [`numpy.dot`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) multiplies two `ndarray`, provided that their dimensions are compatible. The function [`numpy.transpose`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html) returns the transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7rEBgCZkmW8"
   },
   "outputs": [],
   "source": [
    "a = [[1, 0], [0, 1]]\n",
    "b = [[4, 1], [2, 2]]\n",
    "\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8UeoTvskmXA"
   },
   "outputs": [],
   "source": [
    "x = np.arange(4).reshape((2,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QNZbtgZkmXF"
   },
   "outputs": [],
   "source": [
    "np.transpose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTlbEzVnkmXJ"
   },
   "outputs": [],
   "source": [
    "x.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgqrW5aokmXP"
   },
   "source": [
    "**Exercise**: Try to print the average and the standard deviation of the area of those flowers which are *virginica*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vs6x2MUukmXQ"
   },
   "source": [
    "## Dividing the data in training and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjNWR0f2kmXR"
   },
   "source": [
    "Although sometimes we will get the training/test split, knowing dataset spliting tools and alternatives still a common routine for machine learning practitioners. The following code shows a function which randomly divides the dataset, using *vectorized* operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrJz3mTkkmXR"
   },
   "outputs": [],
   "source": [
    "def train_test_split(dataframe, percentage=0.6):\n",
    "    \"\"\" \n",
    "    Function which randomly divide the dataset in training and test\n",
    "    It receives the following parameters:\n",
    "    - dataframe: DataFrame to be divided\n",
    "    - percentage: percentage of training\n",
    "    Returns:\n",
    "    - train: DataFrame with training data\n",
    "    - test: DataFrame with test data\n",
    "    \"\"\"\n",
    "    mask = np.random.rand(len(dataframe)) < percentage\n",
    "    train = dataframe[mask]\n",
    "    test = dataframe[~mask] # what ~ does?\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0Y762a3kmXY"
   },
   "outputs": [],
   "source": [
    "iris_train, iris_test = train_test_split(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsJM2FNQkmXd"
   },
   "source": [
    "Now, we can keep the variables corresponding to the inputs (all but the last one) and the output (in this case, the last one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5WN6YEdkmXe"
   },
   "outputs": [],
   "source": [
    "train_inputs_iris = iris_train.values[:,0:-1]\n",
    "train_outputs_iris = iris_train.values[:,-1]\n",
    "\n",
    "test_inputs_iris = iris_test.values[:,0:-1]\n",
    "test_outputs_iris = iris_test.values[:,-1]\n",
    "\n",
    "print(train_inputs_iris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qu2HdhwkmXj"
   },
   "source": [
    "If we are given the complete dataset to perform the partitions and the validation, all the functions of the module [`sklearn.model_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) from `scikit-learn` can be very helpful (do pay attention to the alternatives for stratification!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "inputs_iris = iris.values[:,0:-1]\n",
    "outputs_iris = iris.values[:,-1]\n",
    "\n",
    "train_inputs_iris, test_inputs_iris, train_outputs_iris, test_outputs_iris = \\\n",
    "       train_test_split(inputs_iris, outputs_iris, test_size=0.33, random_state=42, stratify=outputs_iris)\n",
    "\n",
    "print(train_inputs_iris.shape)\n",
    "print(test_inputs_iris.shape)\n",
    "print([sum(train_outputs_iris==label)/train_outputs_iris.shape[0] for label in np.unique(outputs_iris)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUOQw3_5kmXk"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqW5V6NvkmXm"
   },
   "source": [
    "`scikit-learn` does not allow to use strings for datasets, everything must be a number. For transforming the data, we can use the class [`sklearn.preprocessing.LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html), which automatically converts from string to number. It is used in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxLxqTwskmXm"
   },
   "outputs": [],
   "source": [
    "# Creating the object\n",
    "label_e = preprocessing.LabelEncoder()\n",
    "\n",
    "# 'Training' the encoder \n",
    "label_e.fit(train_outputs_iris)\n",
    "\n",
    "# Applying the conversion\n",
    "train_outputs_iris_encoded = label_e.transform(train_outputs_iris)\n",
    "test_outputs_iris_encoded = label_e.transform(test_outputs_iris)\n",
    "print(train_outputs_iris_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvgwFtlRkmXr"
   },
   "source": [
    "As can be observed, we first create the `LabelEncoder` and then it is trained using the method `fit`. For a `LabelEncoder`, \"training\" means establishing the mapping for the labels, in this case:\n",
    "- `Iris-setosa` -> 0\n",
    "- `Iris-versicolor` -> 1\n",
    "- `Iris-virginica` -> 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_Ka5FMxkmXs"
   },
   "source": [
    "Once trained, we can call to the method `transform` of the `LabelEncoder` to transform any `ndarray` (we would have an error if a test label is new). This API (`fit` method plus `transform` or `predict` method) is common to almost all `scikit-learn` classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQInLttEkmXs"
   },
   "source": [
    "There are many more preprocessing tasks that can be done in `scikit-learn`. Check the module [`sklearn.preprocessing`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9Cy5_MxkmXt"
   },
   "source": [
    "## Creating and evaluating a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgOjlMShkmXu"
   },
   "source": [
    "Now, we are going to create a classification model and obtain the corresponding confusion matrix. We will use the classifier [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), which classifies every pattern by assigning the majority class according to the `k` nearest neighbours with respect to pattern to be classified. You should **always read the documentation** to know more about the parameters of the algorithm, which are always specified in the constructor (in this case, the most important parameter is `n_neighbors`). Let see how the training would be performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yilo2u4dkmXv"
   },
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(train_inputs_iris, train_outputs_iris_encoded)\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDNbPCTvkmX1"
   },
   "source": [
    "The model is trained. This is a *lazy* model, in the sense that there are no parameters to be adjusted during training. The `fit` method only adjust some data structures for the input data, which facilitate the calculation of distances when predicting the label of new data. If we want to obtain the test labels, we can make use of the method `predict`, which applies an already trained model to new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22yGpnzEkmX1"
   },
   "outputs": [],
   "source": [
    "test_prediction = knn.predict(test_inputs_iris)\n",
    "print(test_prediction)\n",
    "print(test_outputs_iris_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAkDcjSikmX6"
   },
   "source": [
    "If we want to know how good the classification has been, every regression or classification model in `scikit-learn` has a method called `score`, which returns the goodness of model predictions against the targets expected, based on the test inputs. The default evaluation metric for [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) is the accuracy (or Correctly Classified Ration, CCR). The function is used in the following way (internally, this function calls to `predict`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIRxJHHGkmX7"
   },
   "outputs": [],
   "source": [
    "accuracy = knn.score(test_inputs_iris, test_outputs_iris_encoded)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ak8PNgPwkmX_"
   },
   "source": [
    "This is similar to perform the comparison and calculate the average (vectorized operations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npDPveXokmYA"
   },
   "outputs": [],
   "source": [
    "np.mean(test_prediction == test_outputs_iris_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtJCKjwfkmYF"
   },
   "source": [
    "To print the confusion matrix of the prediction, we can use the function [`sklearn.metrics.confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9Xva4xYkmYG"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_outputs_iris_encoded, test_prediction)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nb_V_xWkmYL"
   },
   "source": [
    "## Configuring the parameters of a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IINvg8rvkmYM"
   },
   "source": [
    "Imagine that you want to set the number of neighbours (`n_neighbors`) in such a way that training accuracy is as high as possible. This can be done in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJ_2wBuOkmYM"
   },
   "outputs": [],
   "source": [
    "for nn in range(1,15):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=nn)\n",
    "    knn.fit(train_inputs_iris, train_outputs_iris_encoded)\n",
    "    train_accuracy = knn.score(train_inputs_iris, train_outputs_iris_encoded)\n",
    "    test_accuracy = knn.score(test_inputs_iris, test_outputs_iris_encoded)\n",
    "    print(\"%d neighbours: \\tTrain CCR = %.2f%%, \\tTest CCR = %.2f%%\" % (nn, train_accuracy*100, test_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGU8Yf09kmYR"
   },
   "source": [
    "# Exercise to be prepared\n",
    "\n",
    "You have to use the dataset `german` to train two supervised classification models:\n",
    "- One based on the `k` nearest neighbours: [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n",
    "- One based on linear logistic regression: [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "The dataset is in the UCI, with the name [*Statlog (German Credit Data) Data Set*](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29). Download it and preprocess it to perform the training. Divide the data in 60% for training and 40% for test (use the function [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)). You have to normalize all the input variables into the range `[0,1]` (learn about [MinMaxScaler](http://scikit-learn.org/stable/modules/preprocessing.html#scaling-features-to-a-range)). Try to adjust as better as possible the parameters of the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BcQPCqZkmYS"
   },
   "source": [
    "# References\n",
    "This tutorial is mainly based on the following material:\n",
    "- Python como alternativa a R en *machine learning*. Mario Pérez Esteso. [Enlace a Github](https://github.com/MarioPerezEsteso/Python-Machine-Learning). [Enlace a Youtube](https://www.youtube.com/watch?v=8yz4gWt7Klk). \n",
    "- Tutorial from Alex Gramfort and Andreas Mueller [[Github]](https://github.com/amueller/scipy-2018-sklearn)[[Youtube1]](https://www.youtube.com/watch?v=2kT6QOVSgSg)[[Youtube2]](https://www.youtube.com/watch?v=WLYzSas511I)\n",
    "\n",
    "If you want to learn more about `scikit-learn`:\n",
    "- *An introduction to machine learning with scikit-learn*. Official documentation from `scikit-learn`. [http://scikit-learn.org/stable/tutorial/basic/tutorial.html](http://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n",
    "- *A tutorial on statistical-learning for scientific data processing*. Official documentation from `scikit-learn`. [http://scikit-learn.org/stable/tutorial/statistical_inference/index.html](http://scikit-learn.org/stable/tutorial/statistical_inference/index.html).\n",
    "\n",
    "Finally, to learn the basic syntax of Python in less than 13 hours, you can use the following course in *CodeAcademy*:\n",
    "- Python course of CodeAcademy. [https://www.codecademy.com/es/learn/python](https://www.codecademy.com/es/learn/python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aD23G-Dfoi2Q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "tutorialEn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
